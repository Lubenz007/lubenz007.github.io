[
  
  {
    "title": "Copy sharepoint data to Azure Filez",
    "url": "/posts/sharepoint-to-azurefilez/",
    "categories": "Azure",
    "tags": "azure",
    "date": "2025-12-23 00:00:00 +0000",
    "content": "Summary: This PowerShell script copies files and folders from a SharePoint site into an Azure Files share. It supports a -DryRun mode to preview the operations without making changes. The script enumerates folders and files in SharePoint, creates matching directories in Azure Files, downloads files into a temporary location, uploads them into the Azure Files share, and keeps simple statistics about folders and files processed.  Flow diagram:  flowchart TD   A[Start] --&gt; B{DryRun?}   B -- Yes --&gt; C[Scan SharePoint folders &amp; list operations]   B -- No --&gt; D[Connect to SharePoint]   D --&gt; E[Enumerate files &amp; folders]   E --&gt; F{Item Type}   F -- File --&gt; G[Download file -&gt; Upload to Azure Files]   F -- Folder --&gt; H[Ensure Azure Files dir exists -&gt; Recurse]   G --&gt; I[Update stats]   H --&gt; E   C --&gt; I   I --&gt; J[Finish &amp; Report]     &lt;# .SYNOPSIS     Copy files from SharePoint site to Azure Files with automatic folder creation .PARAMETER DryRun     When specified, the script will only list what would be copied without actually copying anything .EXAMPLE     .\\Copy-SharePoint-to-AzureFiles.ps1 -DryRun     Run in dry run mode to preview all operations .EXAMPLE     .\\Copy-SharePoint-to-AzureFiles.ps1     Execute the actual copy operation #&gt;  param(     [switch]$DryRun )  Global statistics $script:Stats = @{     FoldersToCreate = 0     FilesToCopy = 0     TotalSize = 0     FoldersList = @()     FilesList = @() }  Configuration - SharePoint Source $SourceSiteUrl = ‚Äúhttps://xxxx.sharepoint.com/sites/xxxx‚Äù $ClientId = ‚Äúxxxxxxxx-xxxxx-xxxx‚Äù $UseInteractiveLogin = $true # Set to $true to use Interactive login (recommended for Global Admin) $SourceLibrary = ‚Äú‚Äù # Empty - folders are at site root level $SourceRootFolder = ‚Äú‚Äù # Empty because the site URL already points to folder_structure $SubFolders = @(‚Äúxxxxx‚Äù, ‚Äúxxxxx‚Äù, ‚Äúxxxx‚Äù, ‚Äúxxxxx‚Äù, ‚Äúxxxxx‚Äù)  Configuration - Azure Files Destination $StorageAccountName = ‚Äúxx‚Äù  # Change this $FileShareName = ‚Äúxx‚Äù            # Change this $StorageAccountKey = ‚Äúxxx‚Äù     # Change this or use connection string $DestinationRootFolder = ‚Äúxxxxx‚Äù # Root folder in Azure Files  Temporary download location $TempDownloadPath = ‚Äú$env:TEMP\\SharePointToAzureFiles‚Äù  Function to ensure Azure Files directory exists function Initialize-AzureFilesDirectory {     param(         [Parameter(Mandatory = $true)]         [string]$DirectoryPath,         [Parameter(Mandatory = $true)]         $Context,         [switch]$DryRun     )  if ($DryRun) {     Write-Host \"[DRY RUN] Would check/create directory: $DirectoryPath\" -ForegroundColor Cyan     return }  $pathParts = $DirectoryPath.Trim('/').Split('/') $currentPath = \"\"  foreach ($part in $pathParts) {     if ($currentPath -eq \"\") {         $currentPath = $part     } else {         $currentPath = \"$currentPath/$part\"     }          # Check if directory exists     $dir = Get-AzStorageFile -ShareName $FileShareName -Path $currentPath -Context $Context -ErrorAction SilentlyContinue          if ($null -eq $dir) {         Write-Host \"Creating directory: $currentPath\" -ForegroundColor Yellow         try {             $parentPath = if ($currentPath.Contains('/')) {                 $currentPath.Substring(0, $currentPath.LastIndexOf('/'))             } else {                 $null             }                          if ($parentPath) {                 New-AzStorageDirectory -ShareName $FileShareName -Path $currentPath -Context $Context -ErrorAction Stop | Out-Null             } else {                 New-AzStorageDirectory -ShareName $FileShareName -Path $part -Context $Context -ErrorAction Stop | Out-Null             }                          Write-Host \"Created directory: $currentPath\" -ForegroundColor Green         }         catch {             Write-Host \"Error creating directory $currentPath : $_\" -ForegroundColor Red         }     } } }   Function to download and upload files recursively function Copy-FilesRecursively {     param(         [Parameter(Mandatory = $true)]         [string]$SourcePath,         [Parameter(Mandatory = $true)]         [string]$DestinationPath,         [Parameter(Mandatory = $false)]         $AzureContext,         [switch]$DryRun     )  if ($DryRun) {     Write-Host \"`n[DRY RUN] Scanning folder: $SourcePath\" -ForegroundColor Magenta } else {     Write-Host \"`nProcessing folder: $SourcePath\" -ForegroundColor Magenta }  # Debug: Show the exact path being accessed $fullPath = if ($SourceLibrary -eq \"\") { $SourcePath } else { \"$SourceLibrary/$SourcePath\" } Write-Host \"Debug: Attempting to access: $fullPath\" -ForegroundColor Gray  # Get all items in the current folder from SharePoint try {     if ($SourceLibrary -eq \"\") {         $items = Get-PnPFolderItem -FolderSiteRelativeUrl $SourcePath -ItemType All -ErrorAction Stop     } else {         $items = Get-PnPFolderItem -FolderSiteRelativeUrl \"$SourceLibrary/$SourcePath\" -ItemType All -ErrorAction Stop     } } catch {     Write-Host \"Error accessing folder $SourcePath : $($_.Exception.Message)\" -ForegroundColor Red     return }  if ($null -eq $items) {     Write-Host \"No items found in: $SourcePath\" -ForegroundColor Yellow     return }  # Process files foreach ($file in $items | Where-Object { $_.GetType().Name -eq \"File\" }) {     $fileSize = [math]::Round($file.Length / 1MB, 2)          if ($DryRun) {         Write-Host \"[DRY RUN] Would copy file: $($file.Name) (Size: $fileSize MB)\" -ForegroundColor White         $script:Stats.FilesToCopy++         $script:Stats.TotalSize += $file.Length         $script:Stats.FilesList += [PSCustomObject]@{             Name = $file.Name             Source = \"$SourcePath/$($file.Name)\"             Destination = \"$DestinationPath/$($file.Name)\"             Size = $fileSize         }     } else {         Write-Host \"Copying file: $($file.Name) (Size: $fileSize MB)\" -ForegroundColor White                  try {             # Download file from SharePoint to temp location             $tempFilePath = Join-Path $TempDownloadPath $file.Name             $fileUrl = if ($SourceLibrary -eq \"\") { \"$SourcePath/$($file.Name)\" } else { \"$SourceLibrary/$SourcePath/$($file.Name)\" }             Get-PnPFile -Url $fileUrl -AsFile -Path $TempDownloadPath -Filename $file.Name -Force -ErrorAction Stop | Out-Null                          # Upload to Azure Files             Set-AzStorageFileContent -ShareName $FileShareName -Source $tempFilePath -Path \"$DestinationPath/$($file.Name)\" -Context $AzureContext -Force -ErrorAction Stop | Out-Null                          # Clean up temp file             Remove-Item $tempFilePath -Force -ErrorAction SilentlyContinue                          Write-Host \"Successfully copied: $($file.Name)\" -ForegroundColor Green         }         catch {             Write-Host \"Error copying file $($file.Name): $_\" -ForegroundColor Red         }     } }  # Process subfolders recursively foreach ($folder in $items | Where-Object { $_.GetType().Name -eq \"Folder\" }) {     $newSourcePath = \"$SourcePath/$($folder.Name)\"     $newDestinationPath = \"$DestinationPath/$($folder.Name)\"          if (-not $DryRun) {         # Ensure Azure Files directory exists         Initialize-AzureFilesDirectory -DirectoryPath $newDestinationPath -Context $AzureContext     } else {         $script:Stats.FoldersToCreate++         if ($newDestinationPath -notin $script:Stats.FoldersList) {             $script:Stats.FoldersList += $newDestinationPath         }     }          Copy-FilesRecursively -SourcePath $newSourcePath -DestinationPath $newDestinationPath -AzureContext $AzureContext -DryRun:$DryRun } }   Main script execution try {     if ($DryRun) {         Write-Host ‚Äún========================================\" -ForegroundColor Yellow         Write-Host \"DRY RUN MODE - No changes will be made\" -ForegroundColor Yellow         Write-Host \"========================================n‚Äù -ForegroundColor Yellow     }  Write-Host \"Starting copy process...\" -ForegroundColor Cyan Write-Host \"Source: $SourceSiteUrl\" -ForegroundColor Cyan Write-Host \"Destination: Azure Files - $StorageAccountName/$FileShareName\" -ForegroundColor Cyan  # Connect to SharePoint Write-Host \"`nConnecting to SharePoint source site...\" -ForegroundColor Yellow Write-Host \"A browser window will open for authentication...\" -ForegroundColor Cyan try {     if ($UseInteractiveLogin) {         # Use Interactive login (browser-based authentication)         Connect-PnPOnline -Url $SourceSiteUrl -ClientId $ClientId -ErrorAction Stop     } else {         Connect-PnPOnline -Url $SourceSiteUrl -ClientId $ClientId -ErrorAction Stop     }     Write-Host \"Connected to SharePoint successfully\" -ForegroundColor Green } catch {     Write-Host \"Failed to connect to SharePoint: $($_.Exception.Message)\" -ForegroundColor Red     Write-Host \"Make sure pop-ups are allowed in your browser\" -ForegroundColor Yellow     throw }  # Connect to Azure Storage (only for actual copy, not dry run) if (-not $DryRun) {     Write-Host \"`nConnecting to Azure Storage...\" -ForegroundColor Yellow     $azureContext = New-AzStorageContext -StorageAccountName $StorageAccountName -StorageAccountKey $StorageAccountKey     Write-Host \"Connected to Azure Storage successfully\" -ForegroundColor Green          # Ensure temp download directory exists     if (-not (Test-Path $TempDownloadPath)) {         New-Item -ItemType Directory -Path $TempDownloadPath -Force | Out-Null     } } else {     $azureContext = $null }  # Process each subfolder foreach ($subFolder in $SubFolders) {     Write-Host \"`n========================================\" -ForegroundColor Cyan     Write-Host \"Processing subfolder: $subFolder\" -ForegroundColor Cyan     Write-Host \"========================================\" -ForegroundColor Cyan          # Build paths     $sourcePath = if ($SourceRootFolder -eq \"\") { $subFolder } else { \"$SourceRootFolder/$subFolder\" }     $destinationPath = if ($DestinationRootFolder -eq \"\") { $subFolder } else { \"$DestinationRootFolder/$subFolder\" }          # Ensure root destination folder exists (only for non-dry run)     if (-not $DryRun) {         Initialize-AzureFilesDirectory -DirectoryPath $destinationPath -Context $azureContext     }          # Start recursive processing     if ($DryRun) {         Copy-FilesRecursively -SourcePath $sourcePath -DestinationPath $destinationPath -AzureContext $azureContext -DryRun     } else {         Copy-FilesRecursively -SourcePath $sourcePath -DestinationPath $destinationPath -AzureContext $azureContext     } }  if ($DryRun) {     # Display summary statistics     Write-Host \"`n========================================\" -ForegroundColor Yellow     Write-Host \"DRY RUN SUMMARY\" -ForegroundColor Yellow     Write-Host \"========================================\" -ForegroundColor Yellow     Write-Host \"Total folders to create: $($script:Stats.FoldersToCreate)\" -ForegroundColor Cyan     Write-Host \"Total files to copy: $($script:Stats.FilesToCopy)\" -ForegroundColor Cyan     $totalSizeGB = [math]::Round($script:Stats.TotalSize / 1GB, 2)     $totalSizeMB = [math]::Round($script:Stats.TotalSize / 1MB, 2)     Write-Host \"Total size to copy: $totalSizeMB MB ($totalSizeGB GB)\" -ForegroundColor Cyan          Write-Host \"`n--- Folders to be created ---\" -ForegroundColor Yellow     if ($script:Stats.FoldersList.Count -gt 0) {         $script:Stats.FoldersList | ForEach-Object { Write-Host \"  + $_\" -ForegroundColor DarkYellow }     } else {         Write-Host \"  (No new folders needed)\" -ForegroundColor Gray     }          Write-Host \"`n--- Files to be copied ---\" -ForegroundColor Yellow     if ($script:Stats.FilesList.Count -gt 0) {         $script:Stats.FilesList | ForEach-Object {              Write-Host \"  $($_.Name)\" -ForegroundColor White             Write-Host \"    From: $($_.Source)\" -ForegroundColor Gray             Write-Host \"    To:   $($_.Destination)\" -ForegroundColor Gray             Write-Host \"    Size: $($_.Size) MB\" -ForegroundColor Gray         }     } else {         Write-Host \"  (No files to copy)\" -ForegroundColor Gray     }          Write-Host \"`n========================================\" -ForegroundColor Green     Write-Host \"DRY RUN COMPLETED - Ready to execute\" -ForegroundColor Green     Write-Host \"Run without -DryRun to perform actual copy\" -ForegroundColor Green     Write-Host \"========================================\" -ForegroundColor Green } else {     # Clean up temp directory     if (Test-Path $TempDownloadPath) {         Remove-Item $TempDownloadPath -Recurse -Force -ErrorAction SilentlyContinue     }          Write-Host \"`n========================================\" -ForegroundColor Green     Write-Host \"Copy process completed!\" -ForegroundColor Green     Write-Host \"========================================\" -ForegroundColor Green } } catch { Write-Host \"Error in main execution: $_\" -ForegroundColor Red Write-Host $_.Exception.Message -ForegroundColor Red } finally { Disconnect-PnPOnline -ErrorAction SilentlyContinue }"
  },
  
  {
    "title": "Secure Remote Management with Windows Admin Center via Azure Arc and SSH Tunneling.",
    "url": "/posts/ssh-arc-wac/",
    "categories": "Azure",
    "tags": "azure",
    "date": "2025-12-17 00:00:00 +0000",
    "content": "Overview  This guide demonstrates how to securely access Windows Admin Center (WAC) on a remote server using Azure Arc and SSH tunneling. This approach provides a secure, cloud-based connection without exposing your management interface directly to the internet.  What You‚Äôll Achieve     Secure remote access to Windows Admin Center through Azure Arc   SSH tunnel for encrypted port forwarding   Centralized management of multiple servers from a single WAC instance   Leverage WAC extensions (Active Directory, DNS, RDP, etc.) remotely     Prerequisites  Before you begin, ensure you have:     Azure subscription with appropriate permissions   Azure CLI installed on your local machine   Windows Admin Center installed on the target server   Azure Arc agent installed on the server hosting Windows Admin Center   Local administrator credentials for the Arc-enabled server     Architecture  [Your Local Machine]      ‚Üì (Azure CLI + SSH) [Azure Arc Service]     ‚Üì (Secure Connection) [Arc-enabled Server with WAC]       Step-by-Step Guide  Step 1: Install Azure Arc Agent     Navigate to the Azure Portal   Go to Azure Arc &gt; Machines &gt; Add/Create &gt; Add a machine   Select Generate script for your server   Run the generated PowerShell script on your target server as Administrator   The script will:    Install the Azure Connected Machine agent   Register the server with Azure Arc   Create the server resource in your specified resource group   Verify the installation: azcmagent show   Step 2: Install Windows Admin Center     Download Windows Admin Center on the Arc-enabled server   Run the installer with these recommended settings:            Port: 443 (default) or custom port       Certificate: Use self-signed for testing, or provide your own SSL certificate       Allowed client connections: Select based on your security requirements           Complete the installation and verify WAC is accessible locally:     https://localhost:443           Step 3: Authenticate with Azure CLI  On your local machine, authenticate to your Azure tenant:  az login   Follow the browser prompt to complete authentication.  Verify your subscription: az account show   If you have multiple subscriptions, set the correct one: az account set --subscription \"7501db9d-d5f8-4597-8df2-xxxxxxx\"   Step 4: Establish SSH Tunnel via Azure Arc  Use the Azure CLI to create an SSH connection with port forwarding:  az ssh arc \\   --subscription \"7501db9d-d5f8-4597-8df2-xxxxxxxxx\" \\   --resource-group \"hyperv\" \\   --name \"HYPER-01\" \\   --local-user administrator \\   -- -L 3333:192.168.81.101:443   Command Breakdown:    --subscription: Your Azure subscription ID   --resource-group: Resource group containing the Arc-enabled server   --name: Name of the Arc-enabled server   --local-user: Local administrator account on the remote server   -- -L 3333:192.168.81.101:443: Port forwarding configuration            3333: Local port on your machine       192.168.81.101:443: IP and port of the WAC instance (can be localhost or specific IP)           Note: You‚Äôll be prompted for the administrator password.  Step 5: Access Windows Admin Center     Keep the SSH connection active (don‚Äôt close the terminal)   Open your web browser and navigate to:     https://localhost:3333                Accept the security certificate warning (if using self-signed certificate)   Log in with your administrator credentials   Step 6: Manage Your Environment  Once connected to Windows Admin Center, you can:  Add Server Connections     Click Add in Windows Admin Center   Select Server or Windows PC   Enter the hostname or IP address of servers accessible from the Arc-enabled machine   Provide credentials (use saved credentials for convenience)   Install and Use Extensions  Navigate to Settings &gt; Extensions to install:     Active Directory - Manage AD users, groups, and OUs   DNS - Configure DNS zones and records   DHCP - Manage DHCP scopes and reservations   Remote Desktop - Connect to servers via RDP   Failover Clustering - Manage Windows clusters   Hyper-V - Manage virtual machines   And many more‚Ä¶   Manage Multiple Servers  From a single WAC instance, you can now:    Monitor performance across servers   Deploy configurations and updates   Manage certificates and firewall rules   Access Event Viewer and logs   Execute PowerShell scripts     Security Considerations  Best Practices     Use Strong Authentication            Enable Multi-Factor Authentication (MFA) on Azure accounts       Use complex passwords for local administrator accounts       Consider Azure AD integration for WAC           Network Segmentation            Place WAC on a management VLAN/subnet       Restrict firewall rules to necessary ports only       Use Azure Arc with private endpoints when possible           Certificate Management            Replace self-signed certificates with trusted certificates in production       Regularly renew and rotate certificates       Use your organization‚Äôs PKI infrastructure           Audit and Monitoring            Enable Azure Arc logging and monitoring       Review WAC audit logs regularly       Monitor SSH connections through Azure Activity Log           Least Privilege Access            Grant only necessary Azure RBAC roles       Use just-in-time (JIT) access where applicable       Regularly review and revoke unused permissions             Troubleshooting"
  },
  
  {
    "title": "Migrating from VMware to Azure using Azure Files",
    "url": "/posts/Move-VmWare-Azure/",
    "categories": "Azure",
    "tags": "azure",
    "date": "2025-08-18 00:00:00 +0000",
    "content": "When using a tool such as Disk2VHD, you need a storage location‚Äîand sometimes plenty of it‚Äîto export the virtual machine (VM). But what if no local storage is available, and no USB can be connected, such as with a VMware hosting provider?  In that case, you can export the VHD directly to an Azure File Share and then copy it to Azure Blob Storage. Note: Dynamically expanding disks are not supported in this process‚Äîyou must use a fixed-size disk.  The next step is to provision a Windows Server in Azure, install Hyper-V, and use Hyper-V Manager to convert the disk to a fixed-size VHD.  After conversion, you can upload the VHD to Azure, create an image from it, and then deploy a VM. In many cases, Azure will display an error during deployment stating that the VM cannot be customized. You can safely ignore this error.  Tools You Will Need     Disk2VHD ‚Äì for exporting the VMware VM to a VHD file.            üîó Download Disk2VHD           Azure Storage Explorer ‚Äì for managing Azure File Shares and Blob Storage.            üîó Download Azure Storage Explorer           Hyper-V Manager ‚Äì for converting VHDs from dynamic to fixed-size.            Installed on VM in Azure           Step 1: Mount Azure File Share  On the source VMware server and later on the Hyper-V server in Azure, mount the Azure File Share: Mount as Administrator because disk2vhd runs as Administrator.    Step 2: Export VMware VM with Disk2VHD  Run Disk2VHD on the source server.  Select the volumes you want to export.  Choose the Azure File Share as the destination path (after mounting it as a network drive).     Step 3: Convert VHD from Dynamic to Fixed  Open Hyper-V Manager on the Azure VM.  Go to Edit Disk‚Ä¶  Browse to the VHD file from the Azure File Share.  Select Convert ‚Üí Fixed size.    Step 4: Copy VHD to Azure Blob Storage  Use Azure Storage Explorer ( Use copy and paste in the menu :) )    Step 5: Create Azure Managed Image &amp; VM  In the Azure Portal, go to Images ‚Üí + Create.  Select your uploaded VHD as the source.  Create an image.  Deploy a VM from that image.    Now you can create vm from the image.  After deploy you will get deploy error but the Vm is answering rdp and ping.  Prepare Manual.         https://learn.microsoft.com/pt-pt/azure/virtual-machines/windows/prepare-for-upload-vhd-image      New-NetFirewallRule -DisplayName AzurePlatform -Direction Inbound -RemoteAddress 168.63.129.16 -Profile Any -Action Allow -EdgeTraversalPolicy Allow   New-NetFirewallRule -DisplayName AzurePlatform -Direction Outbound -RemoteAddress 168.63.129.16 -Profile Any -Action Allow   Install the Azure Windows VM Agent    https://learn.microsoft.com/en-us/azure/virtual-machines/extensions/agent-windows   And to get rid of the deploy error, change the Size of the VM, that will clear the error."
  },
  
  {
    "title": "Arc - Diskspace Monitoring - Teams)",
    "url": "/posts/OutofDiskspace-Teams/",
    "categories": "Azure, Monitor",
    "tags": "azure, monitor",
    "date": "2023-10-15 02:00:00 +0000",
    "content": "Upon successfully installing Azure Arc on your Server and activating Insights, you open the door to a powerful monitoring capability. One essential aspect is overseeing disk space usage on your server, ensuring optimal performance and preventing potential issues. This example provides a step-by-step guide on how to set up disk space monitoring and receive instant notifications via Microsoft Teams when space is running low.           Furthermore, this versatile approach can be extended to send email alerts, providing an additional layer of flexibility in how you manage critical resource thresholds. This comprehensive monitoring strategy empowers you with the tools to proactively maintain your server‚Äôs health and responsiveness, bolstering the reliability of your operations.           The query below is a simple example of how to monitor disk space usage on your server. It returns the percentage of free space on the C: drive, which is then used to trigger an alert when the threshold is exceeded. The query can be customized to monitor other drives on your server, and the threshold can be adjusted to suit your needs.      InsightsMetrics  | where Name == \"FreeSpaceMB\"  | summarize arg_max(TimeGenerated, *) by Tags, Computer  | extend Drive = tostring(parse_json(Tags)[\"vm.azm.ms/mountId\"])  | extend Size = toreal(parse_json(Tags)[\"vm.azm.ms/diskSizeMB\"])  | project TimeGenerated, Computer, Drive, bin(SizeGB = Size / 1024, 0.1), bin(FreeGB = Val / 1024, 1)  | join kind=inner (InsightsMetrics   | where Name == \"FreeSpacePercentage\"   | summarize arg_max(TimeGenerated, *) by Tags, Computer   | extend Drive = tostring(parse_json(Tags)[\"vm.azm.ms/mountId\"])   | project TimeGenerated, Computer, Drive, bin(FreePercent = Val, 1.1))on Computer, Drive  | project TimeGenerated, Computer, Drive, SizeGB, FreeGB, FreePercent  | where FreePercent &lt;= 90.0 // //| where FreeGB &lt;= 10.0  | order by Computer asc           We need to enable webhooks in Microsoft Teams and copy the webhook URL. Finally, we need to create Azure automation runbook and configure it to send notifications to the channel. We also need to enable the Azure Automation account to access the Log Analytics workspace. To do this, we need to give automation account read access to the Log Analytics workspace and resource group where the arc servers are located.           the runbook code is the following:       # So we are going to use the same query as in Azure Monitor to get the results and send it to Teams   # Connect to Azure for Log Analytics Connect-AzAccount -Identity $context = Set-AzContext -Subscription \"Your Subscription Name\" $workspaceName = \"arc-servers\" $workspaceRG = \"arc-servers\" $WorkspaceID = (Get-AzOperationalInsightsWorkspace -Name $workspaceName -ResourceGroupName $workspaceRG).CustomerID  $query = \"InsightsMetrics | where Name == `\"FreeSpaceMB`\" | summarize arg_max(TimeGenerated, *) by Tags, Computer  | extend Drive = tostring(parse_json(Tags)[`\"vm.azm.ms/mountId`\"])  | extend Size = toreal(parse_json(Tags)[`\"vm.azm.ms/diskSizeMB`\"])  | project TimeGenerated, Computer, Drive, bin(SizeGB = Size / 1024, 0.1), bin(FreeGB = Val / 1024, 1)  | join kind=inner (InsightsMetrics   | where Name == `\"FreeSpacePercentage`\"   | summarize arg_max(TimeGenerated, *) by Tags, Computer   | extend Drive = tostring(parse_json(Tags)[`\"vm.azm.ms/mountId`\"])   | project TimeGenerated, Computer, Drive, bin(FreePercent = Val, 1.1))on Computer, Drive  | project TimeGenerated, Computer, Drive, SizeGB, FreeGB, FreePercent  | where FreePercent &lt;= 90.0 // //| where FreeGB &lt;= 10.0  | order by Computer asc\"  $kqlQuery = Invoke-AzOperationalInsightsQuery -WorkspaceId $WorkspaceID -Query $query  $webhookUri = \"your webhook url\"   # Define the message as a PowerShell object  $message = @{     context   = \"http://schema.org/extensions\"     type      = \"MessageCard\"     themeColor = \"d70000\"     title      = \"Machine with low disk space\"     text = \"$($kqlQuery.results | Format-List | Out-String)\" }  # Convert the message to JSON $jsonMessage = $message | ConvertTo-Json  # Send the message using Invoke-RestMethod Invoke-RestMethod -Method Post -ContentType 'application/json' -Body $jsonMessage -Uri $webhookUri          Select create alert rule            Create a new alert rule            Create action group            Select the runbook with teams notification that we create before           the result in teams"
  },
  
  {
    "title": "Azure Arc - (Azure Cli - ssh - rdp)",
    "url": "/posts/AzureArc-ssh/",
    "categories": "Azure",
    "tags": "azure",
    "date": "2023-10-08 02:00:00 +0000",
    "content": "If you have deployed Azure Arc, you have the option to utilize Windows Admin Center for Windows Machines. Additionally, you can enable the OpenSSH Extension on Windows Server, granting the capability to establish SSH tunnels to the localhost or other machines that support RDP/SSH connections.   To begin the process, please follow these steps:  Ensure that you have the Azure CLI installed on your local computer. If it is not already installed, open PowerShell and execute the command: winget install -e ‚Äìid Microsoft.AzureCLI.  If you are using a different operating system, refer to the official guide on how to install the Azure CLI provided by Microsoft Learn:  How to install the Azure CLI | Microsoft Learn.  Next, enable the OpenSSH extension on the VM where Azure Arc is deployed.         Logon to Azure With Azure CLi   PS C:\\&gt; az login      Please use Multi-Factor Authentication for added security.   The we go to the Connect settings and select password authentication on the VM   Copy the connect string and paste to Powershell and add ‚Äú-L 3333:192.168.x.x:3389‚Äù the ip of the host you want to connect to.  az ssh arc --subscription \"asdfasdfadf-adfadsfadsf-sdfc\" --resource-group \"Arc-Servers\" --name \"HYPER-01\" --local-user \"administrator\" \"-L 3333:192.168.81.25:3389\"       And you are connect over SSH tunnel with RDP."
  },
  
  {
    "title": "hyper-v-tool",
    "url": "/posts/hyper-v-tool/",
    "categories": "Hyper-v",
    "tags": "hyperv",
    "date": "2023-09-30 14:00:00 +0000",
    "content": "My tool to create vm‚Äôs in my lab  https://github.com/Lubenz007/hyper-v-tool  Utilizing a standalone Hyper-V server and generating VMs from a golden image might be considered an older approach, but it‚Äôs one I personally prefer. Over the years, I‚Äôve diligently maintained a tool for crafting VMs on my Hyper-V host within the lab environment. I employ SSH to connect to the Hyper-V host and initiate the VM creation process. This tool provides a streamlined menu system that automatically configures the VM, allowing me to promptly begin using it.         All config is done in the vm_menu.ps1      You can find the oscdimg.exe in the Windows 11 22h2 ADK:   https://learn.microsoft.com/en-us/windows-hardware/get-started/adk-install        Kit ‚ÄúC:\\Program Files (x86)\\Windows Kits\\10\\Assessment and Deployment Kit\\Deployment Tools\\arm64\\Oscdimg‚Äù           $global:oscdimgPath = ‚Äú$global:StartupFolder\\tools\\oscdimg.exe‚Äù      #Template location        $global:template = ‚Äú$global:StartupFolder\\template‚Äù      #template vhd name / windows is sysprep / Ubuntu cloud-init / modify for your template.   $global:2022core = ‚ÄúW2022C.vhdx‚Äù   $global:2022stand = ‚ÄúW2022S_OS.vhdx‚Äù   $global:2022data = ‚ÄúW2022D_OS.vhdx‚Äù   $global:Ubuntu = ‚ÄúUbuntu_OS.vhd‚Äù"
  },
  
  {
    "title": "Get Azure Defender for Cloud score Via API",
    "url": "/posts/DefenderCloudeSecureScore/",
    "categories": "Security",
    "tags": "azure, security",
    "date": "2023-05-28 14:00:00 +0000",
    "content": "How to build a report of Azure Defender for Cloud score Via API, and export it to CSV. Why do we need this? share it with your ?, and show them the progress of your security posture.     Need to create service principal with the following permissions: Read RBAC on each subscription.   #set the variables $ClientID = '' $ClientSecret = '' $tenant_Id = ''  # your subscription Ids $subscription_Ids = ''  # Create the body of the request. $Body = @{         Grant_Type    = \"client_credentials\"     Resource      = \"https://management.azure.com/\"     client_id     = $clientId     client_secret = $clientSecret }  $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body  $Headers = @{     'Content-Type'  = \"application/json\"     'Authorization' = \"Bearer $($ConnectGraph.access_token)\" }  # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12  #function to get graph data with pagination function Get-GraphData {     param (         [parameter(Mandatory)]         [string]$AccessToken,                [parameter(Mandatory)]         [string]$Uri     )      $Headers = @{         'Authorization' = \"Bearer $AccessToken\"     }      do {         $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop          $QueryResults += $Results.value          $Uri = $Results.'@odata.nextLink'     } while ($Uri)      return $QueryResults }  # Get the data foreach ($subscription_Id in $subscription_Ids) {     $uri1 = \"https://management.azure.com/subscriptions/$subscription_Id/providers/Microsoft.Security/secureScores?api-version=2020-01-01\"         [array]$secureScores = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri1     $uri2 = \"https://management.azure.com/subscriptions/$subscription_Id/providers/Microsoft.Security/secureScores/ascScore/securescorecontrols?api-version=2020-01-01\"     [array]$ascScores = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri2     $uri3 = \"https://management.azure.com/subscriptions/$subscription_Id/providers/Microsoft.Security/secureScoreControlDefinitions?api-version=2020-01-01\"     [array]$secureScoreControlDefinitions = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri3     $uri4 = \"https://management.azure.com/subscriptions/$subscription_Id/providers/Microsoft.Security/assessments?api-version=2020-01-01\"     [array]$assessments = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri4     $uri5 = \"https://management.azure.com/subscriptions/$subscription_Id/providers/Microsoft.Security/secureScores/ascScore/securescorecontrols?api-version=2020-01-01&amp;expand=definition\"     [array]$securescorecontrols = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri5 }  # Create the report $ReportLineScore = [PSCustomObject][Ordered]@{       MaxScore   = $secureScores.Properties.score.max     Current    = $secureScores.Properties.score.current     percentage = $secureScores.Properties.score.percentage * 100  }  $SPData = [System.Collections.Generic.List[Object]]::new() ForEach ($ascScore in $ascScores) {     $SPLine = [PSCustomObject][Ordered]@{           Name          = $ascScore.properties.displayName         Healthy       = $ascScore.properties.healthyResourceCount         UnHealthy     = $ascScore.properties.unhealthyResourceCount         NotApplicable = $ascScore.properties.notApplicableResourceCount         weight        = $ascScore.properties.weight         maxScore      = $ascScore.properties.score.max         currentScore  = $ascScore.properties.score.current         percentage    = $ascScore.properties.score.percentage * 100     }     $SPData.Add($SPLine) }  $SPData1 = [System.Collections.Generic.List[Object]]::new() foreach ($secureScoreControlDefinition in $secureScoreControlDefinitions) {     $SPLine1 = [PSCustomObject][Ordered]@{           Name     = $secureScoreControlDefinition.properties.displayName         MaxScore = $secureScoreControlDefinition.properties.maxScore     }     $SPData1.Add($SPLine1) }  $SPData2 = [System.Collections.Generic.List[Object]]::new() foreach ($assessment in $assessments) {     $SPLine2 = [PSCustomObject][Ordered]@{           Name     = $assessment.properties.displayName         Status   = $assessment.properties.status.description         Code     = $assessment.properties.status.code         Cause    = $assessment.properties.status.cause         Details  = $assessment.properties.resourceDetails.Id     }     $SPData2.Add($SPLine2) }  $SPData3 = [System.Collections.Generic.List[Object]]::new() foreach ($securescorecontrol in $securescorecontrols) {     $SPLine3 = [PSCustomObject][Ordered]@{           Name               = $securescorecontrol.properties.displayName         HealthyCount       = $securescorecontrol.properties.healthyResourceCount         UnHealthyCount     = $securescorecontrol.properties.unhealthyResourceCount         NotApplicableCount = $securescorecontrol.properties.notApplicableResourceCount              }     $SPData3.Add($SPLine3) }  $ReportLineScore | Export-Csv -Path \"c:\\temp\\ReportLineScore.csv\" -NoTypeInformation -Encoding UTF8 $SPData | Export-Csv -Path \"c:\\temp\\SPData.csv\" -NoTypeInformation -Encoding UTF8 $SPData1 | Export-Csv -Path \"c:\\temp\\SPData1.csv\" -NoTypeInformation -Encoding UTF8 $SPData2 | Export-Csv -Path \"c:\\temp\\SPData2.csv\" -NoTypeInformation -Encoding UTF8 $SPData3 | Export-Csv -Path \"c:\\temp\\SPData3.csv\" -NoTypeInformation -Encoding UTF8                   MaxScore       Current       percentage                       31       24       77,42                          Name       MaxScore                       Protect applications against DDoS attacks       2                 Enable MFA       10                 Encrypt data in transit       4                 Restrict unauthorized network access       4                 Implement security best practices       0                 Apply adaptive application control       3                 Enable auditing and logging       1                 Enable encryption at rest       4                 Enable endpoint protection       2                 Apply system updates       6                 Manage access and permissions       4                 Remediate security configurations       4                 Secure management ports       8                 Remediate vulnerabilities       6                 Enable enhanced security features       0"
  },
  
  {
    "title": "Monitor Azure Usage for a subscription",
    "url": "/posts/AzureUsageresource/",
    "categories": "Usage",
    "tags": "azure, usage",
    "date": "2023-05-13 14:00:00 +0000",
    "content": "Why do we need to monitor Azure usage? Well, if you have a subscription with a spending limit, you need to keep track of your usage. If you go over the spending limit, your resources will be disabled. And you will need to pay for the overage.     My concern is that some one gets a hold of my subscription, and start to use it. And I will get a big bill at the end of the month.   Using Get-AzConsumptionUsageDetail to get the usage for a subscription. Works not for Azure Plan subscriptions. Bcause of this error: ((400) Subscription scope usage is not supported for current api version. Please use api version after 2019-10-01)     But we can use the Microsoft.Consumption/usageDetails API to get the usage for a subscription.   First we need to create a Service Principal, and we need to give service principal billing role on the subscription.  #This script will get the usage for a subscription  $startDate = (Get-Date).AddDays(-2).ToString(\"yyyy-MM-dd\") $endDate = (Get-Date).AddDays(-1).ToString(\"yyyy-MM-dd\")  #set the variables $ClientID = '' $ClientSecret = '' $tenant_Id = '' $subscriptionId = ''  # Set the URI for the request. $uri1 = \"https://management.azure.com/subscriptions/$subscriptionId/providers/Microsoft.Consumption/usageDetails?api-version=2023-03-01&amp;startDate=${startDate}&amp;endDate=${startDate}\" $uri2 = \"https://management.azure.com/subscriptions/$subscriptionId/providers/Microsoft.Consumption/usageDetails?api-version=2023-03-01&amp;startDate=${endDate}&amp;endDate=${endDate}\"   # Create the body of the request. $Body = @{         Grant_Type    = \"client_credentials\"     Resource      = \"https://management.azure.com/\"     client_id     = $clientId     client_secret = $clientSecret }  $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body  $Headers = @{     'Content-Type'  = \"application/json\"     'Authorization' = \"Bearer $($ConnectGraph.access_token)\" }  # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12   #function to get graph data with pagination function Get-GraphData {     param (         [parameter(Mandatory)]         [string]$AccessToken,                 [parameter(Mandatory)]         [string]$Uri     )      $Headers = @{         'Authorization' = \"Bearer $AccessToken\"     }      do {         $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop          $QueryResults += $Results.value          $Uri = $Results.'@odata.nextLink'     } while ($Uri)      return $QueryResults }  #$useage = Invoke-WebRequest -Method GET -Uri $Uri -ContentType \"application/json\" -Headers $headers | ConvertFrom-Json $uritwodaysago = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri1 $uriyesterday = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri2  $Resultstwodaysago = $uritwodaysago | Select-Object -ExpandProperty properties | Measure-Object -Property costInBillingCurrency -Sum | Select-Object Sum $Resultyesterday = $uriyesterday | Select-Object -ExpandProperty properties | Measure-Object -Property costInBillingCurrency -Sum | Select-Object Sum  $Resultstwodaysago = [math]::Floor($Resultstwodaysago.sum) $Resultyesterday = [math]::ceiling($Resultyesterday.sum) $percentof = [math]::Floor($Resultstwodaysago * 1.4)  if ($Resultstwodaysago -le $percentof -and $Resultyesterday -lt 100) {     Write-Host \"OK: Yesterday's Azure spending ($Resultyesterday Euro) is not 40% more than 2 days ago ($Resultstwodaysago Euro) and not more than 100 Euro | yesterday=$Resultyesterday, spending2daysago=$Resultstwodaysago\" } else {     Write-Host  \"Alarm!! Tom Much Azure Spending\"     $webhookUri = \"webhook from teams\"     $body = @{         \"@context\"   = \"http://schema.org/extensions\"         \"@typecod\"   = \"MessageCard\"         \"themeColor\" = \"d70000\"         \"title\"      = \"Alarm!! To Much Azure Spending\"         \"text\"       = \"Some thing is wrong in Azure. Yesterday's Azure spending ($Resultyesterday Euro) is 40% more than 2 days ago ($Resultstwodaysago Euro) or more than 100 Euro\"     }     Invoke-RestMethod -Uri $webhookUri -Method Post -Body (ConvertTo-Json -InputObject $body)  }"
  },
  
  {
    "title": "Monitor Azure usage with github actions",
    "url": "/posts/AzureUsage/",
    "categories": "Usage",
    "tags": "azure, usage",
    "date": "2023-05-13 14:00:00 +0000",
    "content": "This will not work for Azure Plan subscriptions. ((400) Subscription scope usage is not supported for current api version. Please use api version after 2019-10-01)   Need to keep track of your Azure usage? here is a way to use github actions to keep track of your usage. And send you a Teams message if you are over a certain amount.     We will need to enable webhook in Teams and add the webhook to the script, and create a Service Principal with access to the subscription you want to monitor.   Create Service Principal and give it access to the subscription you want to monitor. Copy the output from the command below and add it to the github repository as a secret, AZURE_CREDENTIALS. az ad sp create-for-rbac --name \"AzureUsage\" --role contributor --scopes /subscriptions/0692777c --sdk-auth       We will need to add secret to the repository, AZURE_CREDENTIALS, and add the output from the command above.    Github actions, it runs every day at midnight.    cron: ‚Äò0 0 * * *‚Äô  # every day at midnight   This is the workflow file # File: .github/workflows/workflow.yml  on:   schedule:    - cron: '0 0 * * *'  # every day at midnight  name: AzureUsage  jobs:    build-and-deploy:     runs-on: ubuntu-latest     steps:          - uses: azure/login@v1       with:         creds: $         enable-AzPSSession: true               - name: Run Azure PowerShell script       uses: azure/powershell@v1       with:         inlinescript: |           $startDate = (Get-Date).AddDays(-2).ToString(\"yyyy-MM-dd\")           $endDate = (Get-Date).AddDays(-1).ToString(\"yyyy-MM-dd\")            $twodaysago = Get-AzConsumptionUsageDetail -StartDate $startDate -EndDate $startDate | Measure-Object -Property PretaxCost -Sum | Select-Object Sum           $yesterday = Get-AzConsumptionUsageDetail -StartDate $enddate -EndDate $enddate | Measure-Object -Property PretaxCost -Sum | Select-Object Sum                                $twodaysago = [math]::Floor($twodaysago.sum)           $yesterday = [math]::ceiling($yesterday.sum)            $percentof = [math]::Floor($twodaysago * 1.4)            if ($twodaysago -le $percentof -and $yesterday -lt 100) {               Write-Host \"OK: Yesterday's Azure spending ($yesterday Euro) is not 40% more than 2 days ago ($twodaysago Euro) and not more than 100 Euro | yesterday=$yesterday, spending2daysago=$twodaysago\"           }           else           {           Write-Host  \"Alarm!! Tom Much Azure Spending\"           $webhookUri = \"webhook from teams\"           $body = @{           \"@context\"   = \"http://schema.org/extensions\"           \"@typecod\"      = \"MessageCard\"           \"themeColor\" = \"d70000\"           \"title\"      = \"Alarm!! To Much Azure Spending\"           \"text\"       = \"Some thing is wrong in Azure. Yesterday's Azure spending ($yesterday Euro) is 40% more than 2 days ago ($twodaysago Euro) or more than 100 Euro\"           }           Invoke-RestMethod -Uri $webhookUri -Method Post -Body (ConvertTo-Json -InputObject $body)            }         azPSVersion: \"latest\""
  },
  
  {
    "title": "Three great tools for Azure",
    "url": "/posts/Three-tool/",
    "categories": "Tools",
    "tags": "azure, tools",
    "date": "2023-05-10 22:00:00 +0000",
    "content": "Always in need for some tools to help make great things.          Azure Quick Review Azure Quick Review (azqr) goal is to produce a high level assessment of an Azure Subscription or Resource Group providing the following information for each Azure Service.           Azure Visualizer PowerShell module to automatically generate Azure resource topology diagrams by just typing a PowerShell cmdlet and passing the name of one or more Azure Resource Group(s).           Azure Cost CLI simple command line tool to get the cost of your Azure subscription."
  },
  
  {
    "title": "Azure Cost CLI",
    "url": "/posts/azure-cost-cli/",
    "categories": "Usage",
    "tags": "azure, usage",
    "date": "2023-05-03 20:00:00 +0000",
    "content": "Azure-Cost-CLI is a new tool to get cost information from Azure. Link  What are the benefits of this tool?, Simple, you can get cost information from Azure without having to log in to the portal. ? Send teams messages with cost information. ? Send emails with cost information. ?  Azure Cost Overview   Accumulated cost for subscription id `0692777c-ed93-4a6a-85c7-144c24xxxx` from **1.5.2023** to **9.5.2023**   Totals                 Period       Amount                       Today       0,90 EUR                 Yesterday       2,21 EUR                 Last 7 days       17,26 EUR                 Last 30 days       19,40 EUR           gantt    title Accumulated cost    dateFormat  X    axisFormat %s    section 01 ma√≠    EUR 2,14 :0, 214    section 02 ma√≠    EUR 4,24 :0, 424    section 03 ma√≠    EUR 6,37 :0, 637    section 04 ma√≠    EUR 8,51 :0, 851    section 05 ma√≠    EUR 11,00 :0, 1100    section 06 ma√≠    EUR 13,61 :0, 1361    section 07 ma√≠    EUR 16,29 :0, 1629    section 08 ma√≠    EUR 18,50 :0, 1850    section 09 ma√≠    EUR 19,40 :0, 1940    section 10 ma√≠    EUR 21,36 : done, 0, 2136    section 11 ma√≠    EUR 23,33 : done, 0, 2333    section 12 ma√≠    EUR 25,52 : done, 0, 2552    section 13 ma√≠    EUR 27,71 : done, 0, 2771    section 14 ma√≠    EUR 30,04 : done, 0, 3004    section 15 ma√≠    EUR 32,19 : done, 0, 3219    section 16 ma√≠    EUR 34,08 : done, 0, 3408    section 17 ma√≠    EUR 35,99 : done, 0, 3599    section 18 ma√≠    EUR 37,91 : done, 0, 3791    section 19 ma√≠    EUR 40,04 : done, 0, 4004    section 20 ma√≠    EUR 42,18 : done, 0, 4218    section 21 ma√≠    EUR 44,46 : done, 0, 4446    section 22 ma√≠    EUR 46,54 : done, 0, 4654    section 23 ma√≠    EUR 48,39 : done, 0, 4839    section 24 ma√≠    EUR 50,24 : done, 0, 5024    section 25 ma√≠    EUR 52,10 : done, 0, 5210    section 26 ma√≠    EUR 54,18 : done, 0, 5418    section 27 ma√≠    EUR 56,26 : done, 0, 5626    section 28 ma√≠    EUR 58,48 : done, 0, 5848    section 29 ma√≠    EUR 60,51 : done, 0, 6051    section 30 ma√≠    EUR 62,30 : done, 0, 6230    section 31 ma√≠    EUR 64,10 : done, 0, 6410   By Service Name                 Service       Amount                       Backup       21,92 EUR                 Security Center       9,88 EUR                 Azure App Service       2,52 EUR                 Virtual Network       1,40 EUR                 Log Analytics       1,21 EUR                 Sentinel       1,00 EUR                 Azure DNS       0,52 EUR                 Storage       0,31 EUR                 Advanced Threat Protection       0,04 EUR                 Others       0,00 EUR           pie    title Cost by service    \"Backup\" : 21.92    \"Security Center\" : 9.88    \"Azure App Service\" : 2.52    \"Virtual Network\" : 1.40    \"Log Analytics\" : 1.21    \"Sentinel\" : 1.00    \"Azure DNS\" : 0.52    \"Storage\" : 0.31    \"Advanced Threat Protection\" : 0.04    \"Others\" : 0.00   By Location                 Location       Amount                       EU West       8,23 EUR                 Unassigned       4,96 EUR                 US West       4,07 EUR                 EU North       1,88 EUR                 Unknown       0,26 EUR           pie    title Cost by location    \"EU West\" : 8.23    \"Unassigned\" : 4.96    \"US West\" : 4.07    \"EU North\" : 1.88    \"Unknown\" : 0.26   By Resource Group                 Resource Group       Amount                       bensa       6,80 EUR                 microsoft.security       4,96 EUR                 backuptest       4,07 EUR                 alitis       2,22 EUR                 test2       1,35 EUR           pie    title Cost by resource group    \"bensa\" : 6.80    \"microsoft.security\" : 4.96    \"backuptest\" : 4.07    \"alitis\" : 2.22    \"test2\" : 1.35   Generated at 2023-05-09 23:33:20"
  },
  
  {
    "title": "Getting old guest accounts in Azure AD",
    "url": "/posts/old-guest-accounts/",
    "categories": "MsGraph",
    "tags": "azure, msgraph",
    "date": "2023-04-26 23:00:49 +0000",
    "content": "This is a rewrite from here office365itpros.com I have added some more properties to the report. And use msgraph instead of mggraph.  # Needs permission User.Read.All  $ClientID = '' $ClientSecret = '' $tenant_Id = '' # Connect to Graph #  $Body = @{       Grant_Type    = \"client_credentials\"   resource      = \"https://graph.microsoft.com\"   client_id     = $clientId   client_secret = $clientSecret }     $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body  # Variable Collections #  $Headers = @{   'Content-Type'  = \"application/json\"   'Authorization' = \"Bearer $($ConnectGraph.access_token)\" }  $token = $ConnectGraph.access_token  # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12  function Get-GraphData {   param (       [parameter(Mandatory)]       [string]$AccessToken,              [parameter(Mandatory)]       [string]$Uri   )    $Headers = @{       'Authorization' = \"Bearer $AccessToken\"   }    do {       $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop        $QueryResults += $Results.value        $Uri = $Results.'@odata.nextLink'   } while ($Uri)    return $QueryResults } #This request get users list with signInActivity. $uri = \"https://graph.microsoft.com/beta/users\"   $Result = @() [array]$Response = Get-GraphData -AccessToken $Token -Uri $uri  if ($Response) {   ForEach ($Respons in $Response) {       $Result += New-Object PSObject -property $([ordered]@{        DisplayName = $Respons.displayName       UserPrincipalName = $Respons.userPrincipalName       UsageLocation = $Respons.usageLocation       Contry = $Respons.country       LastSignInDateTime = if($Respons.signInActivity.lastSignInDateTime) { [DateTime]$Respons.signInActivity.lastSignInDateTime } Else {$null}       IsLicensed  = if ($Respons.assignedLicenses.Count -ne 0) { $true } else { $false }       IsGuestUser  = if ($Respons.userType -eq 'Guest') { $true } else { $false }       RefreshTokensValidFromDateTime = $Respons.RefreshTokensValidFromDateTime       onPremisesDistinguishedName = $Respons.onPremisesDistinguishedName          })   }  } else {   Write-Host \"No User data found\" }  $GuestUsers = $Result | Where-Object{$_.IsGuestUser -eq \"TRUE\"}  $GuestAccountAge = 365 # Value used for guest age comparison. If you want this to be a different value (like 30 days), change this here. #$GuestUsers = $users.value -All $true -Filter \"UserType eq 'Guest'\" | Sort DisplayName $Today = (Get-Date); $StaleGuests = 0 $Report = [System.Collections.Generic.List[Object]]::new() # Check each account and find those over 365 days old ForEach ($Guest in $GuestUsers) {    $AADAccountAge = ($Guest.RefreshTokensValidFromDateTime | New-TimeSpan).Days    If ($AADAccountAge -gt $GuestAccountAge) {       $StaleGuests++       #Write-Host \"Processing\" $Guest.DisplayName       $i = 0; $GroupNames = $Null       # Find what Microsoft 365 Groups the guest belongs to... if any       $ReportLine = [PSCustomObject]@{            UPN     = $Guest.UserPrincipalName            Name    = $Guest.DisplayName            Age     = $AADAccountAge            Created = $Guest.RefreshTokensValidFromDateTime              }            $Report.Add($ReportLine) } } # Output the report $Report | Sort Age -Descending | Format-Table -AutoSize Write-Host \"Found\" $StaleGuests \"stale guest accounts.\"  #reference: https://office365itpros.com/2019/10/15/report-old-guest-accounts/"
  },
  
  {
    "title": "Getting started with Terraform and Azure",
    "url": "/posts/Aztfexport/",
    "categories": "Terraform",
    "tags": "azure, terraform",
    "date": "2023-04-22 18:46:49 +0000",
    "content": "I like to watch videos on how to do things, but i don‚Äôt like to start from scratch. I like to have a template from which i can start and test things out. So start to look out for exporting Azure config to templates. Terraformer is a tool that can export existing cloud infrastructure to Terraform code. But I like aztfexport better because it is more Azure-specific.  Install aztfexport is easy from package manager c:\\winget install aztfexport  And we need also Azure Cli c:\\winget install azure-cli  Login to Azure This was the part I struggled with: where is the config file? It was too simple: login to Azure with Azure Cli and then select the subscription I wanted to export from. Terraform, Terraformer, and aztfexport will use the same subscription as Azure Cli.    So if you try to export and it fails to run, you need to login to Azure Cli.   c:\\az login  Select subscription c:\\az account list -o table c:\\az account set --subscription \"MySubscription\"  Export to Terraform So I start with a simple resource group. And export it to Terraform‚Äôs current folder. c:\\dashboard\\aztfexport rg Dashboard  There will be a menu list, and we will use w to import Terraform files.    Result is a Terraform files So we can start from there and try out things.   The first is to test if the Terraform plan works. c:\\dashboard\\terraform plan   Bingo, the plan works, so we can start to add more resources to the Terraform files."
  },
  
  {
    "title": "Apps Expiration Azure AD",
    "url": "/posts/apps-exp/",
    "categories": "MSGraph",
    "tags": "azure, msgraph",
    "date": "2023-04-07 10:34:00 +0000",
    "content": "This script will check all registered apps in Azure AD and will return the following information: expiring apps, expired apps, and apps with no expiration date.  # needs permission Application.Read.All,Directory.Read.All $ClientID = '' $ClientSecret = '' $tenant_Id = ''  $TenantName = $Body = @{         Grant_Type    = \"client_credentials\"     resource      = \"https://graph.microsoft.com\"     client_id     = $clientId     client_secret = $clientSecret }     $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body  # Variable Collections #  $path = \"C:\\temp\\\" $today = Get-Date  $Headers = @{     'Content-Type'  = \"application/json\"     'Authorization' = \"Bearer $($ConnectGraph.access_token)\" }  $token = $ConnectGraph.access_token  # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12  function Get-GraphData {     param (         [parameter(Mandatory)]         [string]$AccessToken,                [parameter(Mandatory)]         [string]$Uri     )      $Headers = @{         'Authorization' = \"Bearer $AccessToken\"     }      do {         $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop          $QueryResults += $Results.value          $Uri = $Results.'@odata.nextLink'     } while ($Uri)      return $QueryResults }  #This request get application info $uri = \"https://graph.microsoft.com/beta/applications/\"  [array]$apps = Get-GraphData -AccessToken $Token -Uri $uri  $credentials = @()  if ($apps) {     foreach ($app in $apps) {         $ApiUrl = \"https://graph.microsoft.com/beta/applications/\"+$app.id+\"/owners\"         $owner = Invoke-WebRequest -Method GET -Uri $ApiUrl -ContentType \"application/json\" -Headers $headers | ConvertFrom-Json          $app.KeyCredentials | foreach-object {             #write-host $_.KeyId $_.DisplayName             $credentials += [PSCustomObject] @{                 CredentialType = \"KeyCredentials\";                 DisplayName    = $app.DisplayName;                 AppId          = $app.AppId;                 ExpiryDate     = $_.EndDateTime;                 StartDate      = $_.StartDateTime;                 #KeyID = $_.KeyId;                 Type           = $_.Type;                 Usage          = $_.Usage;                 Owners         = $owner.value.userPrincipalName;                 Expired        = (([DateTime]$_.EndDateTime) -lt $today) ? \"Yes\" : \"No\";             }         }          $app.PasswordCredentials | foreach-object {             #write-host $_.KeyId $_.DisplayName             $credentials += [PSCustomObject] @{                 CredentialType = \"PasswordCredentials\";                 DisplayName    = $app.DisplayName;                 AppId          = $app.AppId;                 ExpiryDate     = $_.EndDateTime;                 StartDate      = $_.StartDateTime;                 #KeyID = $_.KeyId;                 Type           = 'NA';                 Usage          = 'NA';                 Owners         = $owner.value.userPrincipalName;                 Expired        = (([DateTime]$_.EndDateTime) -lt $today) ? \"Yes\" : \"No\";             }         }     } } $credentials | Export-Csv -Path $path\\credentials.csv -NoTypeInformation #$credentials | Format-Table | Out-String|ForEach-Object {Write-Host $_}      reference https://pnp.github.io/script-samples/aad-apps-expired-keys/README.html?tabs=graphps"
  },
  
  {
    "title": "Powershell Speedtest",
    "url": "/posts/speedtest/",
    "categories": "Automation",
    "tags": "powershell, automation",
    "date": "2023-04-06 20:15:00 +0000",
    "content": "Was having problems with my internet connection and wanted to monitor it. So I rewrote this script to use powershell and store the results in a table storage.     The script is using the speedtest cli from https://www.speedtest.net/apps/cli   #$StorageAccountName = \"StorageAcount\" #$Key = \"Storagekey\" #$StorageContext = New-AzStorageContext -StorageAccountName $StorageAccountName -StorageAccountKey $Key #$Table = (Get-AzStorageTable -Context $StorageContext | Where-Object {$_.name -eq \"Speedtest\"}).CloudTable $applocation = \"C:\\apps\\speedtest\" $path = \"C:\\temp\\\"  $SpeedTestResults=@() $SpeedtestObj=@()  $i = 0 while ($i -eq 0) {     $PartitionKey = \"1\"     $SpeedTestResults = &amp; \"$($applocation)\\speedtest.exe\" --progress=no --format=json     $SpeedtestResults = $SpeedTestResults | ConvertFrom-Json     $SpeedtestObj += [PSCustomObject] @{         Time = Get-Date -Format \"dd/MM/yyyy HH:mm K\"         downloadspeed = [math]::Round($SpeedtestResults.download.bandwidth / 1000000 * 8, 2)         uploadspeed   = [math]::Round($SpeedtestResults.upload.bandwidth / 1000000 * 8, 2)         packetloss    = ($($SpeedtestResults.packetLoss).ToString(\"P\"))         isp           = $SpeedtestResults.isp         ExternalIP    = $SpeedtestResults.interface.externalIp         InternalIP    = $SpeedtestResults.interface.internalIp         UsedServer    = $SpeedtestResults.server.host         location      = $SpeedTestResults.server.location         Jitter        = [math]::Round($SpeedtestResults.ping.jitter)         Latency       = [math]::Round($SpeedtestResults.ping.latency)            }     # ---- Move to table storage -----     # Add-AzTableRow -table $Table -PartitionKey $PartitionKey -RowKey (Get-Date).Ticks -property $SpeedtestObj         Start-Sleep -Seconds 15 } #$SpeedtestObj | Format-Table | Out-String|ForEach-Object {Write-Host $_} $SpeedtestObj | Export-Csv -Path $path\\speedtest.csv -NoTypeInformation"
  },
  
  {
    "title": "Upgrade Hyper-V Hosts with Azure Arc",
    "url": "/posts/upgrade-hyper/",
    "categories": "Automation",
    "tags": "hyperv, automation",
    "date": "2023-04-04 22:15:00 +0000",
    "content": "Azure Arc is a powerful tool for managing and updating hybrid infrastructure, including standalone Hyper-V hosts. Demo how to use Azure Arc to update a standalone Hyper-V host, using a scheduled update task in Automation Account and pre and post scripts that shut down and start up VMs.  Pre-requisites  # Stop all running VMs on the Hyper-V host and wait for them to shut down # save the names of the running VMs to a file $filePath = \"C:\\temp\\runningvm.txt\" (Get-vm | Where-Object { $_.State -eq \"Running\" }).name | Out-File $filePath  $runningvm = Get-Content $filePath  foreach ($Name in $runningvm) {     Stop-VM $Name      do {         $VM1 = get-vm -Name $Name         Write-Progress -Activity \"Waiting for the VM to shutdown\"      } until ($Null -eq $VM1.Heartbeat)  } # send a webhook to Teams to notify that the VMs have been shut down $webhookUri = \"\" $body = @{ \"@context\" = \"http://schema.org/extensions\" \"@type\" = \"MessageCard\" \"themeColor\" = \"d70000\" \"title\" = \"Send Webhook to Teams\" \"text\" = \"This is a message sent from Powershell\" } Invoke-RestMethod -Uri $webhookUri -Method Post -Body (ConvertTo-Json -InputObject $body)    Post-requisites  # Start up all VMs that were shut down during the update process $filePath = \"C:\\temp\\runningvm.txt\" $runningvm = Get-Content $filePath  foreach ($Name in $runningvm) {     Start-VM $Name     do {         $network = get-vm -name $name | get-VMNetworkAdapter         Write-Progress -Activity \"Waiting for VM Network\"      } until ($network.Status -eq \"ok\")  # Wait for the VM and sleep for 60 seconds for next vm to start ( boot storm if all VMs are started at once) sleep -seconds 60 } # send a webhook to Teams to notify that the VMs have been started $webhookUri = \"\" $body = @{ \"@context\" = \"http://schema.org/extensions\" \"@type\" = \"MessageCard\" \"themeColor\" = \"d70000\" \"title\" = \"Send Webhook to Teams\" \"text\" = \"This is a message sent from Powershell\" } Invoke-RestMethod -Uri $webhookUri -Method Post -Body (ConvertTo-Json -InputObject $body)        Updating a standalone Hyper-V host can be a complex and time-consuming process, but with Azure Arc and Automation Accounts, you can automate much of the work and ensure a smooth, reliable update process. Hyper-v cluster or HCI is a different story."
  },
  
  {
    "title": "Getting licenses assigned to user accounts",
    "url": "/posts/license-report/",
    "categories": "MSGraph",
    "tags": "azure, msgraph",
    "date": "2023-04-01 00:27:00 +0000",
    "content": "Create a report of licenses assigned to Azure AD user accounts using the Microsoft Graph API This is a rewrite from here practical365.com    My misson was to rewrite the script to use the Microsoft Graph API instead of the MgGraph PowerShell module.    $ClientID = '' $ClientSecret = '' $tenant_Id = ''  # Connect to Graph #  $Body = @{         Grant_Type    = \"client_credentials\"     resource      = \"https://graph.microsoft.com\"     client_id     = $clientId     client_secret = $clientSecret }     $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body  # Variable Collections #  $CSVOutputFile = \"c:\\temp\\Microsoft365LicensesReport.CSV\" $today = Get-Date  $Headers = @{     'Content-Type'  = \"application/json\"     'Authorization' = \"Bearer $($ConnectGraph.access_token)\" }  $token = $ConnectGraph.access_token  # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12  function Get-GraphData {     param (         [parameter(Mandatory)]         [string]$AccessToken,                [parameter(Mandatory)]         [string]$Uri     )      $Headers = @{         'Authorization' = \"Bearer $AccessToken\"     }      do {         $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop          $QueryResults += $Results.value          $Uri = $Results.'@odata.nextLink'     } while ($Uri)      return $QueryResults }  #This request get SecureScore  [array]$Skus = Get-GraphData -AccessToken $Token -Uri \"https://graph.microsoft.com/beta/subscribedSkus\" #[Array]$Skus = Get-MgSubscribedSku  # Generate CSV of all product SKUs used in tenant [array]$Sku = $Skus | Select-Object SkuId, SkuPartNumber # Generate list of all service plans used in SKUs in tenant $SPData = [System.Collections.Generic.List[Object]]::new() ForEach ($Sk in $Skus) {     ForEach ($SP in $Sk.ServicePlans) {         $SPLine = [PSCustomObject][Ordered]@{               ServicePlanId          = $SP.ServicePlanId             ServicePlanName        = $SP.ServicePlanName             ServicePlanDisplayName = $SP.ServicePlanName          }         $SPData.Add($SPLine)     } }  $SkuHashTable = @{} ForEach ($Line in $Sku) {      $SkuHashTable.Add([string]$Line.SkuId, [string]$Line.skuPartNumber)  } $ServicePlanHashTable = @{} ForEach ($Line2 in $SPData) { $ServicePlanHashTable.Add([string]$Line2.ServicePlanId, [string]$Line2.ServicePlanDisplayName) }  [Array]$Users = Get-GraphData -AccessToken $Token -Uri \"https://graph.microsoft.com/beta/users\" $Report = [System.Collections.Generic.List[Object]]::new()  ForEach ($User in $users) {     If ([string]::IsNullOrWhiteSpace($User.AssignedLicenses) -eq $true) {        # Only process account if it has some licenses        Write-Host \"Processing\" $User.DisplayName        [array]$LicenseInfo = $Null; [array]$DisabledPlans = $Null        ForEach ($License in $User.AssignedLicenses) {           If ($SkuHashTable.ContainsKey($License.SkuId) -eq $True) {              # We found a match in the SKU hash table              $LicenseInfo += $SkuHashTable.Item($License.SkuId)            }           Else {              # Nothing doing, so output the SkuID              $LicenseInfo += $License            }           # Report any disabled service plans in licenses           If ([string]::IsNullOrWhiteSpace($License.DisabledPlans) -eq $False ) {              # Check if disabled service plans in a license              ForEach ($DisabledPlan in $License.DisabledPlans) {                 # Try and find what service plan is disabled                 If ($ServicePlanHashTable.ContainsKey($DisabledPlan) -eq $True) {                    # We found a match in the Service Plans hash table                    $DisabledPlans += $ServicePlanHashTable.Item($DisabledPlan)                  }                 Else {                    # Nothing doing, so output the Service Plan ID                    $DisabledPlans += $DisabledPlan                  }              } # End ForEach disabled plans           } # End if check for disabled plans          } # End Foreach Licenses        # Report information        [string]$DisabledPlans = $DisabledPlans -join \", \"        [string]$LicenseInfo = $LicenseInfo -join (\", \")        $ReportLine = [PSCustomObject][Ordered]@{             User             = $User.DisplayName           UPN              = $User.UserPrincipalName           Country          = $User.Country           Department       = $User.Department           Title            = $User.JobTitle           Licenses         = $LicenseInfo           \"Disabled Plans\" = $DisabledPlans         }        Write-Host $ReportLine        $Report.Add($ReportLine)     } #end If account is licensed     Else { $UnlicensedAccounts++ }  } # End ForEach Users  $Report | Export-CSV -NoTypeInformation $CSVOutputFile"
  },
  
  {
    "title": "MS Graph API - Get Secure Score for tenant",
    "url": "/posts/SGraph-securescore/",
    "categories": "MSGraph",
    "tags": "azure, msgraph",
    "date": "2023-03-25 22:49:00 +0000",
    "content": "Secure Score for O365 Tenant Getting the secure score for a tenant is a bit more complicated than getting the last logon time of a user. You only need to call the following endpoint: https://graph.microsoft.com/beta/security/secureScores and divide  the result by 100 to get the percentage.  # Needs permission SecurityEvents.Read.All  $ClientID = '' $ClientSecret = '' $tenant_Id = ''  # Connect to Graph #  $Body = @{       Grant_Type    = \"client_credentials\"   resource      = \"https://graph.microsoft.com\"   client_id     = $clientId   client_secret = $clientSecret }     $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body  # Variable Collections #  $path = \"C:\\temp\\\"  $Headers = @{   'Content-Type'  = \"application/json\"   'Authorization' = \"Bearer $($ConnectGraph.access_token)\" }  $token = $ConnectGraph.access_token  # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12  function Get-GraphData {   param (       [parameter(Mandatory)]       [string]$AccessToken,              [parameter(Mandatory)]       [string]$Uri   )    $Headers = @{       'Authorization' = \"Bearer $AccessToken\"   }    do {       $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop        $QueryResults += $Results.value        $Uri = $Results.'@odata.nextLink'   } while ($Uri)    return $QueryResults }  #This request get SecureScore $uri = \"https://graph.microsoft.com/beta/security/secureScores\"  $Result = @() [array]$Response = Get-GraphData -AccessToken $Token -Uri $uri  if ($Response) {     ForEach ($Respons in $Response) {       $SecureScore = $Respons.currentScore / $Respons.maxScore * 100          $Result += New-Object PSObject -property $([ordered]@{            CreatedDateTime   = $Respons.createdDateTime           CurrentScore      = $Respons.currentScore           MaxScore          = $Respons.maxScore           LicensedUserCount = $Respons.licensedUserCount           ActiveUserCount   = $Respons.activeUserCount           SecureScore       = [math]::Round($SecureScore, 2)         })     }     } else {     Write-Host \"No SecureScore data found\" }  # export to csv $Result | export-csv -path \"$path\\SecureScore.csv\" -NoTypeInformation"
  },
  
  {
    "title": "MS Graph API - Get User info",
    "url": "/posts/SGraph-users/",
    "categories": "MSGraph",
    "tags": "azure, msgraph",
    "date": "2023-03-25 13:49:00 +0000",
    "content": "Microsoft Graph API can be used to get the last logon time of a user. To do this, you will need to make a GET request to the /users/{id}/lastLogonTimeStamp endpoint. This endpoint will return the last logon time of the user in the form of a timestamp. You can then use this timestamp to determine the exact date and time of the user‚Äôs last logon.  This query get‚Äôs.    DisplayName,UserPrincipalName,UsageLocation,Contry,LastSignInDateTime,IsLicensed,IsGuestUser   #client_id and client_secret are generated in Azure AD $ClientID = '' $ClientSecret = '' $tenant_Id = ''  # Create the body of the request. $Body = @{         Grant_Type    = \"client_credentials\"     resource      = \"https://graph.microsoft.com\"     client_id     = $clientId     client_secret = $clientSecret }   # Get the access token. $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body  # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12  # Get the access token. $token = $ConnectGraph.access_token  # Variable Collections #   $Result = @()  #This request get users list with signInActivity. $Uri = \"https://graph.microsoft.com/beta/users?$select=displayName,userPrincipalName,contry,UsageLocation,userType,assignedLicenses,signInActivity,lastSignInDateTime&amp;$top=999\"  #function to get graph data with pagination function Get-GraphData {     param (         [parameter(Mandatory)]         [string]$AccessToken,                  [parameter(Mandatory)]         [string]$Uri     )      $Headers = @{         'Authorization' = \"Bearer $AccessToken\"     }      do {         $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop          $QueryResults += $Results.value          $Uri = $Results.'@odata.nextLink'     } while ($Uri)      return $QueryResults }  # Get the users. [array]$Users = Get-GraphData -AccessToken $Token -Uri $uri  # Loop through the results and add them to the output array. ForEach ($User in $Users) {       $Result += New-Object PSObject -property $([ordered]@{              DisplayName        = $User.displayName             UserPrincipalName  = $User.userPrincipalName             UsageLocation      = $user.usageLocation             Contry             = $User.country             LastSignInDateTime = if ($User.signInActivity.lastSignInDateTime) { [DateTime]$User.signInActivity.lastSignInDateTime } Else { $null }             IsLicensed         = if ($User.assignedLicenses.Count -ne 0) { $true } else { $false }             IsGuestUser        = if ($User.userType -eq 'Guest') { $true } else { $false }         }) }   # Write the results to a CSV file. $Logfile = \"lastlogon.csv\" $LogItem = New-Item -ItemType File -Name $Logfile $Result | ConvertTo-Csv | Out-File $LogItem -Append"
  },
  
  {
    "title": "Getting Started with MSGraph API",
    "url": "/posts/SGraph-api/",
    "categories": "MSGraph",
    "tags": "azure, msgraph",
    "date": "2023-03-25 13:49:00 +0000",
    "content": "Authentication and Authorization  MSGraph API is a powerful tool for authentication and authorization that allows developers to access Microsoft services and data. It provides a secure way to authenticate users, authorize applications, and manage user data. With MSGraph API, developers can easily integrate their applications with Microsoft services like Outlook, OneDrive, Office 365, Azure Active Directory, and more. In this article, we‚Äôll explore how to get started with MSGraph API concepts and use cases of the API. Authentication We will use the Azure CLI to create a service principal and get the app id and secret. We will also use the Azure CLI to view all the API permissions available in Microsoft Graph.     Get the Azure CLI from here   # login to Azure az login  #View All API Permissions Microsoft Graph to see what is available $Permissions = az ad sp list --filter \"appId eq '00000003-0000-0000-c000-000000000000'\" | ConvertFrom-Json #to see all permissions $Permissions.appRoles | Select-Object -Property value,allowedMemberTypes,description # Get select permission from list above and id to use in next command $Permissions.appRoles | Select-Object -Property value,allowedMemberTypes,id,description | Where-Object {$_.value -eq \"User.Read.All\"}  # Create service principal az ad app create --display-name \"Alit-GraphAPI\" # Graph API App ID: from output \"appId\": \"d52bda31-bd71-4a17-b563-7921a17d79e7\"  # Reset app secret to get new secret az ad app credential reset --id \"d52bda31-bd71-4a17-b563-7921a17d79e7\" # Graph API App Secret: from output #{ # \"appId\": \"d52bda31-bd71-4a17-b563-7921a17d79e7\", #  \"password\": \"3b3b3b3b-3b3b-3b3b-3b3b-3b3b3b3b3b3b\", #  \"tenant\": \"5eeb8561-5493-4b39-906f-038356850aaa\" #}  # set secret to 3 years #az ad app credential reset --id 13d15b6f-94ad-4df4-a88d-72f355e5f92d --years 3  # Add Microsoft Graph application permission user.read.all # Guide https://learn.microsoft.com/en-us/cli/azure/ad/app/permission?view=azure-cli-latest az ad app permission add --id d52bda31-bd71-4a17-b563-7921a17d79e7 --api 00000003-0000-0000-c000-000000000000 --api-permissions df021288-bdef-4463-88db-98f22de89214=Role  # Grant admin consent #this needs to be done by a Cloud Application Administrator az ad app permission admin-consent --id d52bda31-bd71-4a17-b563-7921a17d79e7  # Get app id  az ad app list --query \"[?displayName=='Alit-GraphAPI'].{id:appId,secret:passwordCredentials[0].value}\" #{ #    \"id\": \"d52bda31-bd71-4a17-b563-7921a17d79e7\", #    \"secret\": null #  }  #get app api permissions az ad app permission list --id d52bda31-bd71-4a17-b563-7921a17d79e7 --output json #{  #   \"resourceAccess\": [  #     {  #       \"id\": \"df021288-bdef-4463-88db-98f22de89214\",  #       \"type\": \"Role\"  #     }  #   ],  #   \"resourceAppId\": \"00000003-0000-0000-c000-000000000000\"  # }   Reference:    nielskok.tech   how-to-create-service-principal-portal   how-to-authenticate-service-principal-cli   how to-add-app-roles-in-azure-ad-apps"
  }
  
]

